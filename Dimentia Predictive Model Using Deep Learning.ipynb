{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimentia Predictive Model Using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Four_1\":{\"0\":-30.094},\"Four_2\":{\"0\":-157.137},\"Four_3\":{\"0\":-16.844},\"Four_4\":{\"0\":-1.129},\"Four_5\":{\"0\":66.137},\"Four_6\":{\"0\":-51.188},\"Four_7\":{\"0\":-32.82},\"Four_8\":{\"0\":4.687},\"Four_9\":{\"0\":-43.879},\"Four_10\":{\"0\":-15.527},\"Four_11\":{\"0\":23.102},\"Four_12\":{\"0\":-25.242},\"Four_13\":{\"0\":-25.758},\"Four_14\":{\"0\":2.539},\"Four_15\":{\"0\":33.531},\"Four_16\":{\"0\":10.031},\"Four_17\":{\"0\":-12.059},\"Four_18\":{\"0\":18.902},\"Four_19\":{\"0\":8.727},\"Four_20\":{\"0\":40.279},\"Four_21\":{\"0\":61.79},\"Four_22\":{\"0\":-5.787},\"Four_23\":{\"0\":6.367},\"Four_24\":{\"0\":13.895},\"Four_25\":{\"0\":47.0},\"Four_26\":{\"0\":25.029},\"Four_27\":{\"0\":15.921},\"Four_28\":{\"0\":29.875},\"Four_29\":{\"0\":-5.786},\"Four_30\":{\"0\":-11.912},\"Four_31\":{\"0\":30.913},\"Four_32\":{\"0\":21.224},\"Four_33\":{\"0\":-27.371},\"Four_34\":{\"0\":-24.361},\"Four_35\":{\"0\":-0.692},\"Four_36\":{\"0\":-2.845},\"Four_37\":{\"0\":-18.036},\"Four_38\":{\"0\":-7.389},\"Four_39\":{\"0\":-18.281},\"Four_40\":{\"0\":-17.246},\"Four_41\":{\"0\":-6.164},\"Four_42\":{\"0\":-6.038},\"Four_43\":{\"0\":1.095},\"Four_44\":{\"0\":-16.593},\"Four_45\":{\"0\":-17.991},\"Four_46\":{\"0\":-6.297},\"Four_47\":{\"0\":-13.637},\"Four_48\":{\"0\":-6.035},\"Four_49\":{\"0\":-6.88},\"Four_50\":{\"0\":-15.351},\"Four_51\":{\"0\":-12.96},\"Four_52\":{\"0\":-10.203},\"Four_53\":{\"0\":-7.618},\"Four_54\":{\"0\":-3.605},\"Four_55\":{\"0\":-14.402},\"Four_56\":{\"0\":-7.776},\"Four_57\":{\"0\":-1.407},\"Four_58\":{\"0\":-0.67},\"Four_59\":{\"0\":-3.926},\"Four_60\":{\"0\":-0.874},\"Four_61\":{\"0\":0.785},\"Four_62\":{\"0\":4.45},\"Four_63\":{\"0\":4.88},\"Four_64\":{\"0\":-0.319},\"Four_65\":{\"0\":3.654},\"Four_66\":{\"0\":-4.002},\"Four_67\":{\"0\":-1.658},\"Four_68\":{\"0\":-1.946},\"Four_69\":{\"0\":-4.709},\"Four_70\":{\"0\":-5.305},\"Four_71\":{\"0\":-1.931},\"Four_72\":{\"0\":-1.832},\"Four_73\":{\"0\":1.936},\"Four_74\":{\"0\":-3.935},\"Four_75\":{\"0\":1.687},\"Four_76\":{\"0\":1.235},\"Four_77\":{\"0\":0.18},\"Four_78\":{\"0\":-2.152},\"Four_79\":{\"0\":1.355},\"Four_80\":{\"0\":3.922},\"Four_81\":{\"0\":1.336},\"Four_82\":{\"0\":6.805},\"Four_83\":{\"0\":0.438},\"Four_84\":{\"0\":2.711},\"Four_85\":{\"0\":-1.266},\"Four_86\":{\"0\":0.105},\"Four_87\":{\"0\":-0.012},\"Four_88\":{\"0\":-2.633},\"Four_89\":{\"0\":-2.035},\"Four_90\":{\"0\":-1.695},\"Four_91\":{\"0\":0.074},\"Four_92\":{\"0\":1.328},\"Four_93\":{\"0\":-3.098},\"Four_94\":{\"0\":2.664},\"Four_95\":{\"0\":1.398},\"Four_96\":{\"0\":3.5},\"Four_97\":{\"0\":-0.344},\"Four_98\":{\"0\":2.877},\"Four_99\":{\"0\":3.219},\"Four_100\":{\"0\":5.353},\"Four_101\":{\"0\":6.574},\"Four_102\":{\"0\":5.33},\"Four_103\":{\"0\":6.463},\"Four_104\":{\"0\":-0.642},\"Four_105\":{\"0\":1.657},\"Four_106\":{\"0\":2.253},\"Four_107\":{\"0\":-0.548},\"Four_108\":{\"0\":0.057},\"Four_109\":{\"0\":0.018},\"Four_110\":{\"0\":2.287},\"Four_111\":{\"0\":2.837},\"Four_112\":{\"0\":2.283},\"Four_113\":{\"0\":4.266},\"Four_114\":{\"0\":5.922},\"Four_115\":{\"0\":9.859},\"Four_116\":{\"0\":6.387},\"Four_117\":{\"0\":11.453},\"Four_118\":{\"0\":11.944},\"Four_119\":{\"0\":20.811},\"Four_120\":{\"0\":19.359},\"Four_121\":{\"0\":13.851},\"Four_122\":{\"0\":19.656},\"Four_123\":{\"0\":7.902},\"Four_124\":{\"0\":10.847},\"Four_125\":{\"0\":13.919},\"Four_126\":{\"0\":4.835},\"Four_127\":{\"0\":7.374},\"Four_128\":{\"0\":10.734},\"Four_129\":{\"0\":14.673},\"Four_130\":{\"0\":23.597},\"Four_131\":{\"0\":11.23},\"Four_132\":{\"0\":14.526},\"Four_133\":{\"0\":18.712},\"Four_134\":{\"0\":-7.264},\"Four_135\":{\"0\":-13.347},\"Four_136\":{\"0\":-3.856},\"Four_137\":{\"0\":-1.169},\"Four_138\":{\"0\":5.521},\"Four_139\":{\"0\":-2.908},\"Four_140\":{\"0\":-1.368},\"Four_141\":{\"0\":-1.428},\"Four_142\":{\"0\":-8.622},\"Four_143\":{\"0\":-8.479},\"Four_144\":{\"0\":-5.348},\"Four_145\":{\"0\":-10.14},\"Four_146\":{\"0\":-11.601},\"Four_147\":{\"0\":-7.621},\"Four_148\":{\"0\":-7.844},\"Four_149\":{\"0\":0.482},\"Four_150\":{\"0\":-9.8},\"Four_151\":{\"0\":-5.135},\"Four_152\":{\"0\":1.763},\"Four_153\":{\"0\":-8.484},\"Four_154\":{\"0\":-8.746},\"Four_155\":{\"0\":-4.477},\"Four_156\":{\"0\":-4.934},\"Four_157\":{\"0\":-2.309},\"Four_158\":{\"0\":1.891},\"Four_159\":{\"0\":-6.367},\"Four_160\":{\"0\":-5.234},\"Four_161\":{\"0\":-7.902},\"Four_162\":{\"0\":-6.59},\"Four_163\":{\"0\":-9.875},\"Four_164\":{\"0\":-6.055},\"Four_165\":{\"0\":-8.125},\"Four_166\":{\"0\":-8.398},\"Four_167\":{\"0\":-7.539},\"Four_168\":{\"0\":-7.172},\"Four_169\":{\"0\":-6.184},\"Four_170\":{\"0\":-2.293},\"Four_171\":{\"0\":0.992},\"Four_172\":{\"0\":-7.264},\"Four_173\":{\"0\":-13.347},\"Four_174\":{\"0\":-3.856},\"Four_175\":{\"0\":-1.169},\"Four_176\":{\"0\":5.521},\"Four_177\":{\"0\":-2.908},\"Four_178\":{\"0\":-1.368},\"Four_179\":{\"0\":-1.428},\"Four_180\":{\"0\":-8.622},\"Four_181\":{\"0\":-8.479},\"Four_182\":{\"0\":-5.348},\"Four_183\":{\"0\":-10.14},\"Four_184\":{\"0\":-11.601},\"Four_185\":{\"0\":-7.621},\"Four_186\":{\"0\":-7.844},\"Four_187\":{\"0\":0.482},\"Four_188\":{\"0\":-9.8},\"Four_189\":{\"0\":-5.135},\"Four_190\":{\"0\":1.763},\"Four_191\":{\"0\":9.859},\"Four_192\":{\"0\":6.387},\"Four_193\":{\"0\":11.453},\"Four_194\":{\"0\":11.944},\"Four_195\":{\"0\":20.811},\"Four_196\":{\"0\":19.359},\"Four_197\":{\"0\":13.851},\"Four_198\":{\"0\":19.656},\"Four_199\":{\"0\":7.902},\"Four_200\":{\"0\":10.847},\"Four_201\":{\"0\":13.919},\"Four_202\":{\"0\":4.835},\"Four_203\":{\"0\":7.374},\"Four_204\":{\"0\":10.734},\"Four_205\":{\"0\":14.673},\"Four_206\":{\"0\":23.597},\"Four_207\":{\"0\":11.23},\"Four_208\":{\"0\":14.526},\"Four_209\":{\"0\":18.712},\"Four_210\":{\"0\":3.5},\"Four_211\":{\"0\":-0.344},\"Four_212\":{\"0\":2.877},\"Four_213\":{\"0\":3.219},\"Four_214\":{\"0\":5.353},\"Four_215\":{\"0\":6.574},\"Four_216\":{\"0\":5.33},\"Four_217\":{\"0\":6.463},\"Four_218\":{\"0\":-0.642},\"Four_219\":{\"0\":1.657},\"Four_220\":{\"0\":2.253},\"Four_221\":{\"0\":-0.548},\"Four_222\":{\"0\":0.057},\"Four_223\":{\"0\":0.018},\"Four_224\":{\"0\":2.287},\"Four_225\":{\"0\":2.837},\"Four_226\":{\"0\":2.283},\"Four_227\":{\"0\":4.266},\"Four_228\":{\"0\":5.922},\"Four_229\":{\"0\":0.18},\"Four_230\":{\"0\":-2.152},\"Four_231\":{\"0\":1.355},\"Four_232\":{\"0\":3.922},\"Four_233\":{\"0\":1.336},\"Four_234\":{\"0\":6.805},\"Four_235\":{\"0\":0.438},\"Four_236\":{\"0\":2.711},\"Four_237\":{\"0\":-1.266},\"Four_238\":{\"0\":0.105},\"Four_239\":{\"0\":-0.012},\"Four_240\":{\"0\":-2.633},\"Four_241\":{\"0\":-2.035},\"Four_242\":{\"0\":-1.695},\"Four_243\":{\"0\":0.074},\"Four_244\":{\"0\":1.328},\"Four_245\":{\"0\":-3.098},\"Four_246\":{\"0\":2.664},\"Four_247\":{\"0\":1.398},\"Four_248\":{\"0\":-0.67},\"Four_249\":{\"0\":-3.926},\"Four_250\":{\"0\":-0.874},\"Four_251\":{\"0\":0.785},\"Four_252\":{\"0\":4.45},\"Four_253\":{\"0\":4.88},\"Four_254\":{\"0\":-0.319},\"Four_255\":{\"0\":3.654},\"Four_256\":{\"0\":-4.002},\"Four_257\":{\"0\":-1.658},\"Four_258\":{\"0\":-1.946},\"Four_259\":{\"0\":-4.709},\"Four_260\":{\"0\":-5.305},\"Four_261\":{\"0\":-1.931},\"Four_262\":{\"0\":-1.832},\"Four_263\":{\"0\":1.936},\"Four_264\":{\"0\":-3.935},\"Four_265\":{\"0\":1.687},\"Four_266\":{\"0\":1.235},\"Four_267\":{\"0\":-18.281},\"Four_268\":{\"0\":-17.246},\"Four_269\":{\"0\":-6.164},\"Four_270\":{\"0\":-6.038},\"Four_271\":{\"0\":1.095},\"Four_272\":{\"0\":-16.593},\"Four_273\":{\"0\":-17.991},\"Four_274\":{\"0\":-6.297},\"Four_275\":{\"0\":-13.637},\"Four_276\":{\"0\":-6.035},\"Four_277\":{\"0\":-6.88},\"Four_278\":{\"0\":-15.351},\"Four_279\":{\"0\":-12.96},\"Four_280\":{\"0\":-10.203},\"Four_281\":{\"0\":-7.618},\"Four_282\":{\"0\":-3.605},\"Four_283\":{\"0\":-14.402},\"Four_284\":{\"0\":-7.776},\"Four_285\":{\"0\":-1.407},\"Four_286\":{\"0\":40.279},\"Four_287\":{\"0\":61.79},\"Four_288\":{\"0\":-5.787},\"Four_289\":{\"0\":6.367},\"Four_290\":{\"0\":13.895},\"Four_291\":{\"0\":47.0},\"Four_292\":{\"0\":25.029},\"Four_293\":{\"0\":15.921},\"Four_294\":{\"0\":29.875},\"Four_295\":{\"0\":-5.786},\"Four_296\":{\"0\":-11.912},\"Four_297\":{\"0\":30.913},\"Four_298\":{\"0\":21.224},\"Four_299\":{\"0\":-27.371},\"Four_300\":{\"0\":-24.361},\"Four_301\":{\"0\":-0.692},\"Four_302\":{\"0\":-2.845},\"Four_303\":{\"0\":-18.036},\"Four_304\":{\"0\":-7.389}}\n",
      "Index(['Four_1', 'Four_2', 'Four_3', 'Four_4', 'Four_5', 'Four_6', 'Four_7',\n",
      "       'Four_8', 'Four_9', 'Four_10',\n",
      "       ...\n",
      "       'Four_295', 'Four_296', 'Four_297', 'Four_298', 'Four_299', 'Four_300',\n",
      "       'Four_301', 'Four_302', 'Four_303', 'Four_304'],\n",
      "      dtype='object', length=304)\n"
     ]
    }
   ],
   "source": [
    "#making the data mapped in a more complex pattern\n",
    "from sklearn.datasets import make_circles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#get the training data\n",
    "original_training=pd.read_csv(\".\\\\ADvsHCFourier.csv\")\n",
    "original_training.head(10)\n",
    "X_train=original_training.copy()\n",
    "\n",
    "\n",
    "del X_train['class']\n",
    "del X_train['experiment']\n",
    "X_train.head()\n",
    "print(X_train[0:1].to_json())\n",
    "\n",
    "#get the columns of the data set from the data frame\n",
    "print(X_train.columns)\n",
    "#print(\"print the training data X : \\n\",X_train)\n",
    "\n",
    "\n",
    "y_train = []\n",
    "\n",
    "for data in original_training ['class']:\n",
    "    y_train.append(data)\n",
    "#below code encode the classes ['AD','HCI'] into [0,1]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "Y_train = encoder.transform(y_train)\n",
    "#print(\"print train data y values  :\",Y_train)    \n",
    "\n",
    "#getting the test dataset\n",
    "test_data= pd.read_csv(\".\\\\ADvsHCFourier_test.csv\")\n",
    "X_test=test_data.copy()\n",
    "del X_test['class']\n",
    "del X_test['experiment']\n",
    "X_test.head(8)\n",
    "#print(\"print test X data : \\n\",X_test)\n",
    "\n",
    "\n",
    "y_test=[]\n",
    "for t_data in test_data ['class']:\n",
    "    y_test.append(t_data)\n",
    "\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(y_test)\n",
    "Y_test = encoder.transform(y_test)\n",
    "    \n",
    "#print(\"print test data y values :\",Y_test)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model using Keras (Backend Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras.optimizers import Adam #will do the back prop to optimize the model\n",
    "\n",
    "#Generalized Pattern for the Sequential Model is in steps as follows\n",
    "    \n",
    "    ##Create Model##\n",
    "model= Sequential() #simple Sequential Model(layers are added one after the other)\n",
    "    \n",
    "    ##Add Layers##    \n",
    "model.add(Dense(304,activation=\"relu\",kernel_initializer='uniform',input_dim=304))\n",
    "        #'1'- 0ne neuron/\n",
    "        #'input_shape=(2,)'means that we are inputting (x,y) data pairs\n",
    "        #'activation=\"sigmoid\"' is the activation function of the neuron\n",
    "        #model.add(Dense(10,activation=\"tanh\"))\n",
    "#model.add(Dense(12,kernel_initializer='normal',activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(12,kernel_initializer='normal',activation=\"relu\"))\n",
    "#lets add a Dropout layer to reduce the overfitting of model..change the para value to change the accuracy\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(12,kernel_initializer='normal',activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12,kernel_initializer='normal',activation=\"relu\"))\n",
    "model.add(Dense(12,kernel_initializer='normal',activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(1,kernel_initializer='normal',activation=\"sigmoid\"))\n",
    "    \n",
    "    ##Compile Model##\n",
    "model.compile(Adam(lr=0.01),'binary_crossentropy',metrics=['accuracy'])\n",
    "        #'Adam(lr=0.05)' is used to minimize the error\n",
    "        #'binary_crossentropy' function is used to calculate the loss\n",
    "        #'metrics=['accuracy']' is the metric we want to optimize\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the Model using the above data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 9ms/step\n",
      "\n",
      "\n",
      "Test Loss: 10.513352394104004 Test Accuracy : 0.09090909361839294\n"
     ]
    }
   ],
   "source": [
    "     ##Train Model##\n",
    "model.fit(X_train,Y_train,epochs=250,verbose=0)\n",
    "        #'epochs=100' how many times your are running through the data\n",
    "    \n",
    "        ##Evaluate Performance##\n",
    "eval_result=model.evaluate(X_test,Y_test)\n",
    "    \n",
    "print(\"\\n\\nTest Loss:\",eval_result[0],\"Test Accuracy :\",eval_result[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model_json=model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file :\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model.h5\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [404]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nj = r.json()\\n\\ndf = pd.DataFrame([[d['v'] for d in x['c']] for x in j['rows']],\\n                  columns=[d['label'] for d in j['cols']])\\n                  \\n                  \""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "r = requests.get('http://0.0.0.0/detect')\n",
    "\n",
    "\n",
    "j = r.json()\n",
    "\n",
    "df = pd.DataFrame([[d['v'] for d in x['c']] for x in j['rows']],\n",
    "                  columns=[d['label'] for d in j['cols']])\n",
    "                  \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
